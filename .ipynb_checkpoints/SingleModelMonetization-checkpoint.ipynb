{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Model Monetization - Part 2\n",
    "### CSCI 4210 - Simulation and Modeling\n",
    "#### Matthew Wicker\n",
    "\n",
    "In this notebook, we will reload our pretrained model. Then, we will attempt to exploit this models prediction to maximize profits (or to minimize losses!).\n",
    "### Getting started - Clone the DeepMarketModels Repository:\n",
    "\n",
    "#### â€¢ From your terminal run the following command: git clone https://github.com/matthewwicker/DeepMarketModels.git\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (16, 10)\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "#===========================================================\n",
    "#          We have set these for reproducibility\n",
    "#===========================================================\n",
    "\n",
    "np.random.seed(5)\n",
    "look_back = 7\n",
    "\n",
    "#===========================================================\n",
    "#      Constants which define the stock you want to use\n",
    "#===========================================================\n",
    "\n",
    "# Here is the path to your finacial data from Yahoo:\n",
    "# Note: Replace NVIDIA stock. Not enough data on recent trends\n",
    "STOCK_TO_USE = \"AAPL\"\n",
    "DATA_PATH = \"FinData/\" + STOCK_TO_USE + \".csv\"\n",
    "MODEL_JSON_PATH = \"FinModels/\" + STOCK_TO_USE + \".json\"\n",
    "MODEL_WEIGHT_PATH = \"FinModels/\" + STOCK_TO_USE + \".h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data that we will be using\n",
    "\n",
    "This is the same as in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening File: FinData/AAPL.csv\n",
      "Done reading file\n"
     ]
    }
   ],
   "source": [
    "# Here are the basic values of each stock that we have information on\n",
    "class date:\n",
    "    def __init__(self):\n",
    "        self.date = \"NaN\"\n",
    "        self.open = 0.0\n",
    "        self.high = 0.0\n",
    "        self.low = 0.0\n",
    "        self.close = 0.0\n",
    "        self.adj = 0.0\n",
    "        self.volume = 0.0\n",
    "    def reinit(self, date, op, high, low, close, adj, vol):\n",
    "        self.date = date\n",
    "        self.open = float(op)\n",
    "        self.high = float(high)\n",
    "        self.low = float(low)\n",
    "        self.close = float(close)\n",
    "        self.adj = float(adj)\n",
    "        self.volume = float(vol)\n",
    "        \n",
    "data_entries = []\n",
    "print (\"Opening File: %s\"%(DATA_PATH))\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if('null' in row): continue;\n",
    "        if(i == 0): continue;\n",
    "        temp_date = date()\n",
    "        temp_date.reinit(row[0], row[1], row[2], row[3], row[4], row[5], row[6])\n",
    "        data_entries.append(temp_date)\n",
    "        \n",
    "dates_of_data = np.asarray([i.date for i in data_entries])\n",
    "open_of_data = np.asarray([i.open for i in data_entries])\n",
    "close_of_data = np.asarray([i.close for i in data_entries])\n",
    "high_of_data = np.asarray([i.high for i in data_entries])\n",
    "low_of_data = np.asarray([i.low for i in data_entries])\n",
    "\n",
    "dates_of_data = dates_of_data[-2500:]\n",
    "open_of_data = open_of_data[-2500:]\n",
    "close_of_data = close_of_data[-2500:]\n",
    "high_of_data = high_of_data[-2500:]\n",
    "low_of_data = low_of_data[-2500:]\n",
    "\n",
    "\n",
    "print(\"Done reading file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [1,look_back,1]\n",
    "model = Sequential()\n",
    "d = 0.1\n",
    "model = Sequential()    \n",
    "model.add(LSTM(32, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "model.add(Dropout(d))\n",
    "        \n",
    "model.add(Dense(4,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "\n",
    "model.load_weights(MODEL_WEIGHT_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Train Split (just as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = open_of_data\n",
    "stock_prices = stock_prices.reshape(len(stock_prices), 1)\n",
    "\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "stock_prices = scaler.fit_transform(stock_prices)\n",
    "\n",
    "train_size = int(len(stock_prices) * 0.95)\n",
    "test_size = len(stock_prices) - train_size\n",
    "train, test = stock_prices[0:train_size,:], stock_prices[train_size:len(stock_prices),:]\n",
    "\n",
    "print('Split data into training set and test set... Number of training samples/ test samples:', len(train), len(test))\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# convert stock price data into time series dataset\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input of the LSTM to be format [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "\n",
    "# Here is where some things are different: \n",
    "testX_E = testX[:100]\n",
    "testX_P = testX[:-25]\n",
    "\n",
    "\n",
    "print(\"Done with split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a relevent measure of our data based on some unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# invert predictions and targets to unscaled\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainY = trainY.reshape(len(trainY[0]), 1)\n",
    "testY = testY.reshape(len(testY[0]), 1)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "# shift predictions of training data for plotting\n",
    "trainPredictPlot = np.empty_like(stock_prices)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift predictions of test data for plotting\n",
    "testPredictPlot = np.empty_like(stock_prices)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(stock_prices)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.clf()\n",
    "plt.title(\"Results of our Prediction for %s Stock Prices [Close]\"%(STOCK_TO_USE))\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Price\")\n",
    "test_size = 125\n",
    "\n",
    "real = close_of_data[-test_size:]\n",
    "pred = testPredictPlot[-test_size:]\n",
    "\n",
    "c, = plt.plot(real[:100], label='Close Price',alpha=0.3)\n",
    "predict_test, = plt.plot(pred[:100], label='LSTM Prediction on Unseen Data', color='r')\n",
    "plt.legend(handles=[c, predict_test])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objects = ('Python', 'C++', 'Java', 'Perl', 'Scala', 'Lisp')\n",
    "cod = real[:100]\n",
    "lstmp = pred[:100]\n",
    "performance = [lstmp[i] - cod[i] for i in range(100)]\n",
    "y_pos = np.arange(len(performance))\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('Spectral_r')\n",
    "max_val = 50\n",
    "colors = []\n",
    "for i in performance:\n",
    "    color_val = cmap(abs(i)/max_val)\n",
    "    hex_col = '#%02x%02x%02x' % (color_val[0][0]*255, color_val[0][1]*255, color_val[0][2]*255)\n",
    "    colors.append(hex_col)\n",
    "\n",
    "\n",
    "    \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5,width=1.0, color=colors)\n",
    "plt.ylabel('Difference in USD ($)')\n",
    "plt.title('Prediction Accuracy - Difference between Predicted Close and Real Close - %s'%(STOCK_TO_USE))\n",
    "plt.xlabel('Day')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "max_val += 1\n",
    "pylab.rcParams['figure.figsize'] = (16, 1)\n",
    "plt.clf()\n",
    "ones = np.ones(max_val)\n",
    "color_val = [cmap(float(i)/max_val)for i in range(max_val)]\n",
    "plt.bar(np.arange(max_val), ones, align='center', alpha=0.5,width=1.0, color=color_val)\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,50])\n",
    "plt.title(\"Chart for Difference Plot Color per USD ($)\")\n",
    "plt.show()\n",
    "pylab.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning the visuals into something useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets seperate the negative values from the \n",
    "# positive values so we can get a sense of if we \n",
    "# are over predicting or under predicting\n",
    "cmap = matplotlib.cm.get_cmap('hot_r')\n",
    "cod = real[:100]\n",
    "lstmp = pred[:100]\n",
    "\n",
    "negs = [lstmp[i] - cod[i] for i in range(100) if((lstmp[i] - cod[i]) < 0)]\n",
    "poss = [lstmp[i] - cod[i] for i in range(100) if((lstmp[i] - cod[i]) > 0)]\n",
    "\n",
    "negs = np.asarray(negs)\n",
    "poss = np.asarray(poss)\n",
    "\n",
    "print(\"Number of overshoots: %s Average Overshoot Val: %s\"%(len(poss), np.average(poss)))\n",
    "print(\"Number of undershoots: %s Average Undershoot Val: %s\"%(len(negs), np.average(negs)))\n",
    "# After getting the trend of over or under predicting\n",
    "# we will figure out the average overshoot and \n",
    "# undershoot\n",
    "\n",
    "real = close_of_data[-test_size:]\n",
    "pred = testPredictPlot[-test_size:]\n",
    "\n",
    "overshoot =  np.average(poss)\n",
    "undershoot =  np.average(negs)\n",
    "naive_bet = (overshoot+undershoot)/2\n",
    "\n",
    "x_vals = np.arange(25)\n",
    "\n",
    "pred_ub = [i-overshoot for i in pred[-25:]]\n",
    "pred_lb = [i-undershoot for i in pred[-25:]]\n",
    "pred_b = [i-naive_bet for i in pred[-25:]]\n",
    "r = plt.scatter(x_vals, pred[-25:], label=\"Predicted Values\", alpha=0.3, color=cmap(0.6))\n",
    "l = plt.scatter(x_vals, pred_ub, label=\"Predicted Stock Lower Bound\", alpha=0.3, color=cmap(0.4))\n",
    "u = plt.scatter(x_vals, pred_lb, label=\"Predicted Stock Upper Bound\", alpha=0.3, color=cmap(1.0))\n",
    "b = plt.errorbar(x_vals, pred_b, yerr=overshoot, label=\"Value to Bet On\", alpha=0.2, color=cmap(0.8))\n",
    "b = plt.errorbar(x_vals, pred_b, yerr=undershoot, label=\"Value to Bet On\", alpha=0.2, color=cmap(0.8))\n",
    "o, = plt.plot(real[-25:], label='Close Price',alpha=0.3)\n",
    "plt.legend(handles=[r,l,u,b,o])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using under and overshoot to trade this stock\n",
    "\n",
    "* If we predict that the current price will certainly go up (even under lower bound conditions) then we want a strong  investment\n",
    "\n",
    "* If we predict that the current price may go up on the average case we will make a relatively strong investment\n",
    "\n",
    "* If we predict that the stock may go up, but has a higher chance of going down then we invest very weakly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = real[-25:]\n",
    "vals = pred_b\n",
    "\n",
    "investment_rec = []\n",
    "\n",
    "\n",
    "#This strategy constant will determine how aggressive the investment strategy is. \n",
    "# 10 - conservative \n",
    "# 20 - optimistic\n",
    "# 30 - aggressive\n",
    "# 40 - insanity\n",
    "STRATEGY_CONSTANT = 10\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if(i == len(data)-1):\n",
    "        break\n",
    "    if(data[i] < pred_ub[i+1]):\n",
    "        inv = STRATEGY_CONSTANT*(1 - data[i]/pred_lb[i+1])\n",
    "        investment_rec.append(inv)\n",
    "        continue\n",
    "    elif(data[i] < pred_b[i+1]):\n",
    "        inv = (STRATEGY_CONSTANT/2)*(1 - data[i]/pred_lb[i+1])\n",
    "        investment_rec.append(inv)\n",
    "    elif(data[i] < pred_lb[i+1]):\n",
    "        inv = 1 - data[i]/pred_lb[i+1]\n",
    "        investment_rec.append(inv)\n",
    "    else:\n",
    "        investment_rec.append(0)\n",
    "        \n",
    "for i in range(len(investment_rec)):\n",
    "    if(investment_rec[i] > 1):\n",
    "        investment_rec[i] = 1\n",
    "\n",
    "x = np.arange(len(investment_rec))  \n",
    "plt.title(\"Investment Strategy Profile\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Amount of Original Amount to Invest in this Stock\")\n",
    "plt.bar(x, investment_rec, alpha=0.2, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So how much money do we make (or lose)?\n",
    "\n",
    "Now that we have the amounts that we will invest based on our confidence in the model, let's see what the payoff would be for following this strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_AMOUNT = float(100)\n",
    "\n",
    "inv_perf = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if(i == len(data)-1):\n",
    "        break\n",
    "    total_invested = TOTAL_AMOUNT * investment_rec[i]\n",
    "    #print(\"Investing: \", total_invested)\n",
    "    TOTAL_AMOUNT-=total_invested\n",
    "    returned = total_invested*float(data[i+1]/data[i])\n",
    "    #print(\"Return: \", returned)\n",
    "    TOTAL_AMOUNT+=returned\n",
    "    inv_perf.append(returned-total_invested)\n",
    "zero = np.zeros(len(inv_perf))\n",
    "print(\"Total Percent Gain with this Investment Strategy: %s\"%((TOTAL_AMOUNT-100)[0]))\n",
    "plt.title(\"Percent Profit and Loss per Day\")\n",
    "plt.xlabel(\"Day of Investment\")\n",
    "plt.ylabel(\"Percent Return\")\n",
    "k, = plt.plot(inv_perf, label=\"Cumulative Gain/Loss: %.3f (Percent)\"%((TOTAL_AMOUNT-100)[0]))\n",
    "z, = plt.plot(zero, label=\"Zero Gain/Loss Line\", color='r', alpha=0.2)\n",
    "plt.legend(handles=[k,z])\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we do over all of our models?\n",
    "\n",
    "Here, we plot a bar chart which tells us the gain and loss of our naive investment strategy on each of the market models we trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = [3.572, -1.146, -0.229, 0.056, -0.643, 0.032, -0.252, -0.340, 0.128, 0.001, 0.075, 0.263, -4, 0.312, 1.949, -0.108, 0.658, 0.126, -0.329]          \n",
    "performance = sort(performance)\n",
    "sum_p = sum(performance)\n",
    "\n",
    "colors = []\n",
    "for i in performance:\n",
    "    if(i < 0):\n",
    "        colors.append('r')\n",
    "    else:\n",
    "        colors.append('g')\n",
    "\n",
    "x = np.arange(len(performance)) \n",
    "plt.title(\"Total performance of all models in percentage\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Performance (Percent)\")\n",
    "b = plt.bar(x, performance, color=colors, alpha=0.3, label=\"Total Gain: +%.3f\"%(sum_p) )\n",
    "plt.legend(handles=[b])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
